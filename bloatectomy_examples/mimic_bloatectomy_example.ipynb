{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bloatectomy on MIMIC III \n",
    "+ Concatenating notes for each admission into one document\n",
    "+ This concatenation step is necessary for running bloatectomy on the MIMICiii database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import psycopg2\n",
    "import numpy\n",
    "from sqlalchemy import create_engine, update, event\n",
    "from bloatectomy import bloatectomy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a mistake is made the connection will need to be closed before running again. uncomment the lines below to reset\n",
    "#conn.commit()\n",
    "#cur.close()\n",
    "#conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSTGRES_CONNECT = os.environ.get(\"POSTGRES_CONNECT\")\n",
    "#or enter here in the format\n",
    "# POSTGRES_CONNECT = psycopg2.connect(\"dbname=mimic user=postgres_username password=postgres_password options=--search_path=mimiciii\");\n",
    "\n",
    "POSTGRES_ENGINE = os.environ.get(\"POSTGRES_ENGINE\")\n",
    "#or enter here in the format\n",
    "# POSTGRES_ENGINE = create_engine('postgresql://postgres_username:postgres_password@localhost/mimic'\n",
    "\n",
    "#connect to posgres\n",
    "conn = psycopg2.connect(POSTGRES_CONNECT)\n",
    "engine = create_engine(POSTGRES_ENGINE)\n",
    "cur = conn.cursor();\n",
    "\n",
    "#set search path for the mimic schema in postgres\n",
    "cur.execute(\"\"\"SET search_path = mimiciii;\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  One Document per Admission\n",
    "\n",
    "For each admission, concatenate all the notes for that admission into one note (thus, each admission has one **document**). Create a table of these admission notes using the hospital admission id (hadm_id) as the identifier rather than the note id (row_id)\n",
    "\n",
    "### Notes by Admission `notes_concatenated` with or without metadata\n",
    "+ group by admission ID\n",
    "+ order by note date ('note_dt')\n",
    "+ concatenate all notes for that admission ID into one string\n",
    "+ metadata==True: concatenate all notes and other data (date(s), provider=cgid, note, type=category,description) for that admission ID into one string\n",
    "+ save as notes_concatenated or notes_concatenated_metadata\n",
    "\n",
    "###  Create  new table for results `notes_concatenated` or `notes_concatenated_metadata`\n",
    "+ hadm_id\n",
    "+ text (concatenate notes and/or other data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set whether you want to include metadata at the top of each note (we don't use this for the NLP, but is' useful for the viewing by SMEs)\n",
    "metadata = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if metadata==False:\n",
    "    cur.execute(\"\"\"DROP TABLE IF EXISTS mimiciii.notes_concatenated;\n",
    "    CREATE TABLE mimiciii.notes_concatenated\n",
    "    (hadm_id int,\n",
    "     text varchar);\"\"\") \n",
    "else:\n",
    "    cur.execute(\"\"\"DROP TABLE IF EXISTS mimiciii.notes_concatenated_metadata;\n",
    "    CREATE TABLE mimiciii.notes_concatenated_metadata\n",
    "    (hadm_id int,\n",
    "     text varchar);\"\"\")\n",
    "conn.commit();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the specific hadm_ids for this operation. Try with a few to make sure it's working\n",
    "xf = pd.read_sql(\"\"\"\n",
    "SELECT hadm_id\n",
    "FROM mimiciii.noteevents LIMIT 10 \"\"\", engine)\n",
    "\n",
    "xf_ids = xf.hadm_id.unique()\n",
    "#xf_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function that lets us make multiple  requests to the postgres using pandas read_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@event.listens_for(engine, 'before_cursor_execute')\n",
    "def receive_before_cursor_execute(conn, cursor, statement, params, context, executemany):\n",
    "    if executemany:\n",
    "        cursor.fast_executemany = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to pull notes, concatenate and save\n",
    "\n",
    "+ this will take a few hours to run for about half of the hadm_ids in the database\n",
    "+ iterate through for each unique admission (hadm_id)\n",
    "+ pull all notes for an admission\n",
    "+ order notes by charttime , then storetime\n",
    "+ concatenate\n",
    "+ save as one big note to new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in xf_ids:\n",
    "    \n",
    "    if metadata == False:\n",
    "        table_name = 'notes_concatenated'\n",
    "        sql = \"\"\"\n",
    "        SELECT  hadm_id, chartdate, charttime, storetime, text\n",
    "        FROM mimiciii.noteevents \n",
    "            WHERE hadm_id in ({0})\n",
    "        GROUP BY hadm_id, chartdate, charttime, storetime, text\n",
    "        ORDER BY chartdate, charttime, storetime\"\"\"\n",
    "\n",
    "        # run sql query above to pull all notes for one admission (in order by date)\n",
    "        sql = sql.format(j)\n",
    "        xnotes=pd.read_sql(sql, engine)      \n",
    "        xnotes = xnotes.loc[:,'text']\n",
    "    \n",
    "    else: \n",
    "        table_name = 'notes_concatenated_metadata'\n",
    "        sql = \"\"\"\n",
    "        SELECT subject_id, hadm_id, chartdate, charttime, storetime, category, cgid, description, text\n",
    "        FROM mimiciii.noteevents \n",
    "            WHERE hadm_id in ({0})\n",
    "        GROUP BY subject_id, hadm_id, chartdate, charttime, storetime, category, cgid, description, text\n",
    "        ORDER BY chartdate, charttime, storetime\"\"\"\n",
    "\n",
    "        # run sql query above to pull all notes for one admission (in order by date)\n",
    "        # concatenate notes and all other cols (metadata)\n",
    "        # all the metadata gets put into one token for duplicate removal purposes\n",
    "        sql = sql.format(j)\n",
    "        xnotes=pd.read_sql(sql, engine)\n",
    "        xnotes.loc[:,'text2'] = xnotes.loc[:,'text'] \n",
    "        xnotes.iloc[:,-2] = '. '\n",
    "        \n",
    "    # put a a period + whitespace to designate the end start and end of a note     \n",
    "    xnotes['separator'] = '. '\n",
    "    xtext = xnotes.to_csv(None, header=False, index=False) \n",
    "    # save as a new dataframe\n",
    "    xtext2 = [(j, xtext)]\n",
    "    xfulltext=pd.DataFrame(xtext2, columns=['hadm_id', 'text'])\n",
    "    # append user and single note to the new table in database\n",
    "    xfulltext.to_sql(table_name, con=engine, if_exists='append', chunksize=1, index=False, schema='mimiciii')\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the new table into pandas for inspection\n",
    "notes_concat = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM mimiciii.notes_concatenated\"\"\", engine)\n",
    "#notes_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bloatectomy\n",
    "Bloatectomize mimiciii data by passing a list of hadm_ids and the table name where the concatenated notes are located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling notes from postgres database\n",
      "highlighting duplications in ID 167853\n",
      "Output file = ./output/mimic_167853.html\n",
      "highlighting duplications in ID 107527\n",
      "Output file = ./output/mimic_107527.html\n",
      "highlighting duplications in ID 167118\n",
      "Output file = ./output/mimic_167118.html\n",
      "highlighting duplications in ID 196489\n",
      "Output file = ./output/mimic_196489.html\n",
      "highlighting duplications in ID 135453\n",
      "Output file = ./output/mimic_135453.html\n",
      "highlighting duplications in ID 170490\n",
      "Output file = ./output/mimic_170490.html\n",
      "highlighting duplications in ID 134727\n",
      "Output file = ./output/mimic_134727.html\n",
      "highlighting duplications in ID 114236\n",
      "Output file = ./output/mimic_114236.html\n",
      "highlighting duplications in ID 163469\n",
      "Output file = ./output/mimic_163469.html\n",
      "highlighting duplications in ID 189681\n",
      "Output file = ./output/mimic_189681.html\n"
     ]
    }
   ],
   "source": [
    "bloatectomy(xf_ids, style='highlight', output='html', filename='./output/mimic', postgres_table='mimiciii.notes_concatenated', postgres_engine=engine);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling notes from postgres database\n",
      "highlighting duplications in ID 167853\n",
      "Output file = bloatectomized_file_167853.html\n",
      "highlighting duplications in ID 167118\n",
      "Output file = bloatectomized_file_167118.html\n"
     ]
    }
   ],
   "source": [
    "list_example = [167853,167118]\n",
    "bloatectomy(list_example, style='highlight', output='html',  postgres_table='mimiciii.notes_concatenated', postgres_engine=engine);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
